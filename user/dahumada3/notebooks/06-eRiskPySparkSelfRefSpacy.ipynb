{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5152580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-erisk25task1EDA.ipynb     04-eRiskAnalysisSelfReferential.ipynb\n",
      "01-erisktokenestimate.ipynb  05-eRiskPySparkSelfRefFiltering.ipynb\n",
      "03-pyterrier-test2.ipynb     06-eRiskPySparkSelfRefSpacy.ipynb\n",
      "/storage/home/hcoda1/6/dahumada3/clef/erisk-2025/user/dahumada3/notebooks\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916cfeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/28 01:58:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/28 01:58:12 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://atl1-1-03-003-3-2.pace.gatech.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[24]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1555259b57b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/storage/home/hcoda1/6/dahumada3/clef/erisk-2025\")\n",
    "\n",
    "from erisk.spark import get_spark\n",
    "\n",
    "spark = get_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2a5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "LABELS_MAJ_PATH = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/raw/training_data/2023/g_qrels_majority_2.csv\"\n",
    "LABELS_CONS_PATH = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/raw/training_data/2023/g_rels_consenso.csv\"\n",
    "PARQUET_DIR = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/parquet/training_data/2023/partitions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c512aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DOCNO: string (nullable = true)\n",
      " |-- TEXT: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 2:============================================>              (3 + 1) / 4]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------------------------------------------------------------------+\n",
      "|DOCNO       |TEXT                                                                                 |\n",
      "+------------+-------------------------------------------------------------------------------------+\n",
      "|s_2457_109_0|LADWP, Inyo agree to test run on well 395                                            |\n",
      "|s_2457_110_0|State representatives recognize NIHDs District of Year designation                   |\n",
      "|s_2457_111_0|Small plane crashes en route from Bishop to Nanaimo, BC (Canada)                     |\n",
      "|s_2457_112_0|Audio and video production professionals, as an example: https://youtu.be/jv5HIrOrn2o|\n",
      "|s_2457_113_0|Sure, its a professional powerhouse for audio and video production professionals.    |\n",
      "+------------+-------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(PARQUET_DIR)\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e06f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+\n",
      "|TEXT                                                                             |\n",
      "+---------------------------------------------------------------------------------+\n",
      "|LADWP, Inyo agree to test run on well 395                                        |\n",
      "|State representatives recognize NIHDs District of Year designation               |\n",
      "|Small plane crashes en route from Bishop to Nanaimo, BC (Canada)                 |\n",
      "|Audio and video production professionals, as an example:                         |\n",
      "|Sure, its a professional powerhouse for audio and video production professionals.|\n",
      "+---------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows: 4264560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Dataframe cleanup\n",
    "from pyspark.sql.functions import col, trim\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df_clean = df.filter(trim(col(\"TEXT\")) != \"\")\n",
    "df_clean = df_clean.withColumn(\"TEXT\", regexp_replace(\"TEXT\", r\"http\\S+|www\\S+\", \"\"))\n",
    "df_clean.select(\"TEXT\").show(5, truncate=False)\n",
    "\n",
    "print(\"Remaining rows:\", df_clean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbd650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "SELF_REF_PATTERN = r\"\\b(i|me|my|mine|myself|i'm|i’ve|i'd|i’ll|i am|i was)\\b\"\n",
    "\n",
    "df_with_flag = df_clean.withColumn(\n",
    "    \"is_self_ref\", lower(col(\"TEXT\")).rlike(SELF_REF_PATTERN)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb6867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-referential posts: 1,191,200 out of 4,264,560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "self_ref_df = df_with_flag.filter(col(\"is_self_ref\"))\n",
    "\n",
    "total_count = df_with_flag.count()\n",
    "self_ref_count = self_ref_df.count()\n",
    "\n",
    "print(f\"Self-referential posts: {self_ref_count:,} out of {total_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2dc790a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+\n",
      "|       DOCNO|                TEXT|is_self_ref|\n",
      "+------------+--------------------+-----------+\n",
      "|s_2457_109_0|LADWP, Inyo agree...|      false|\n",
      "|s_2457_110_0|State representat...|      false|\n",
      "|s_2457_111_0|Small plane crash...|      false|\n",
      "|s_2457_112_0|Audio and video p...|      false|\n",
      "|s_2457_113_0|Sure, its a profe...|      false|\n",
      "+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_flag.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a97796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "SELF_REF_WORDS = {\n",
    "    \"i\",\n",
    "    \"me\",\n",
    "    \"my\",\n",
    "    \"mine\",\n",
    "    \"myself\",\n",
    "    \"i'm\",\n",
    "    \"i’ve\",\n",
    "    \"i'd\",\n",
    "    \"i’ll\",\n",
    "    \"i am\",\n",
    "    \"i was\",\n",
    "}\n",
    "\n",
    "\n",
    "def spacy_self_ref_ratio(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.text for token in doc if not token.is_space]\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    self_ref_count = sum(1 for token in tokens if token in SELF_REF_WORDS)\n",
    "    return self_ref_count / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "229131d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "def process_partition_with_spacy(partition):\n",
    "    import spacy\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "    SELF_REF_WORDS = {\n",
    "        \"i\",\n",
    "        \"me\",\n",
    "        \"my\",\n",
    "        \"mine\",\n",
    "        \"myself\",\n",
    "        \"i'm\",\n",
    "        \"i’ve\",\n",
    "        \"i'd\",\n",
    "        \"i’ll\",\n",
    "        \"i am\",\n",
    "        \"i was\",\n",
    "    }\n",
    "\n",
    "    for row in partition:\n",
    "        text = row[\"TEXT\"]\n",
    "        doc = nlp(text.lower())\n",
    "        tokens = [token.text for token in doc if not token.is_space]\n",
    "        if not tokens:\n",
    "            ratio = 0.0\n",
    "        else:\n",
    "            self_ref_count = sum(1 for token in tokens if token in SELF_REF_WORDS)\n",
    "            ratio = self_ref_count / len(tokens)\n",
    "\n",
    "        yield Row(**row.asDict(), self_ref_ratio=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5ff78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Completed in 36.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Your Spark transformation\n",
    "df_with_ratio = df_with_flag.rdd.mapPartitions(process_partition_with_spacy).toDF()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"⏱️ Completed in {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45159f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+--------------+\n",
      "|       DOCNO|                TEXT|is_self_ref|self_ref_ratio|\n",
      "+------------+--------------------+-----------+--------------+\n",
      "|s_2457_109_0|LADWP, Inyo agree...|      false|           0.0|\n",
      "|s_2457_110_0|State representat...|      false|           0.0|\n",
      "|s_2457_111_0|Small plane crash...|      false|           0.0|\n",
      "|s_2457_112_0|Audio and video p...|      false|           0.0|\n",
      "|s_2457_113_0|Sure, its a profe...|      false|           0.0|\n",
      "+------------+--------------------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/28 02:03:14 WARN PythonRunner: Detected deadlock while completing task 2.0 in stage 19 (TID 98): Attempting to kill Python Worker\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_ratio.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6222db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+-----------+-------------------+\n",
      "|TEXT                                                                                    |is_self_ref|self_ref_ratio     |\n",
      "+----------------------------------------------------------------------------------------+-----------+-------------------+\n",
      "|LADWP, Inyo agree to test run on well 395                                               |false      |0.0                |\n",
      "|State representatives recognize NIHDs District of Year designation                      |false      |0.0                |\n",
      "|Small plane crashes en route from Bishop to Nanaimo, BC (Canada)                        |false      |0.0                |\n",
      "|Audio and video production professionals, as an example:                                |false      |0.0                |\n",
      "|Sure, its a professional powerhouse for audio and video production professionals.       |false      |0.0                |\n",
      "|I have no use for an equally expensive cnc milling machine, either.                     |true       |0.07142857142857142|\n",
      "|But I wont pretend that there is no market out there for them.                          |true       |0.06666666666666667|\n",
      "|I could use a cheap 3D printer for my needs, or even my schools needs.                  |true       |0.17647058823529413|\n",
      "|But industry professionals would pay top dollar for a cnc milling machine.              |false      |0.0                |\n",
      "|Dont you think professional video production houses would use the heck out of a Mac Pro?|false      |0.0                |\n",
      "+----------------------------------------------------------------------------------------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_ratio.select(\"TEXT\", \"is_self_ref\", \"self_ref_ratio\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5eb3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------------------------------------------------------------------------------------------------------------+-----------+--------------------+\n",
      "|DOCNO       |TEXT                                                                                                                       |is_self_ref|self_ref_ratio      |\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------+-----------+--------------------+\n",
      "|s_2457_120_0|Thanks, Im really looking forward to using the new gear.                                                                   |false      |0.07692307692307693 |\n",
      "|s_2457_120_1|The only piece Im nervous about is the Sawyer Micro.                                                                       |false      |0.08333333333333333 |\n",
      "|s_2457_120_2|Ive watched some YouTube video reviews complaining that they tend to block up with just routine use.                       |false      |0.05263157894736842 |\n",
      "|s_2457_130_4|Oh, the shear pins Im familiar with were placed through a housing on the gearbox, through the brake disc.                  |false      |0.043478260869565216|\n",
      "|s_2457_161_1|The Hardware ID is different (0x0000, and not 0x7002) and the Mnaufacturer info is missing altogether (not \"Apple Inc.\"). [|false      |0.03333333333333333 |\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_ratio.filter((col(\"self_ref_ratio\") > 0) & (~col(\"is_self_ref\"))).show(\n",
    "    5, truncate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------------+\n",
      "|DOCNO       |TEXT                                                                                                                                                                       |is_self_ref|self_ref_ratio|\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------------+\n",
      "|s_2457_131_0| gt;I can imagine that the forces are far greater - a 3ft long blade (from root to tip) on an aircraft is nothing compared to the 300+ foot long monsters on wind turbines.|true       |0.0           |\n",
      "|s_3020_36_0 |[Translation](  gt;my method of healing as of late!!!                                                                                                                      |true       |0.0           |\n",
      "|s_3020_51_0 |[Translation](  gt;my selfies heh                                                                                                                                          |true       |0.0           |\n",
      "|s_3020_78_1 | gt;I'm so so glad that MOAs liked it  gt;There really isn't much time left now, for real.                                                                                 |true       |0.0           |\n",
      "|s_3020_82_0 |uuuuh...[i'm sorry](                                                                                                                                                       |true       |0.0           |\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/28 02:26:34 WARN PythonRunner: Detected deadlock while completing task 2.0 in stage 25 (TID 113): Attempting to kill Python Worker\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_ratio.filter((col(\"is_self_ref\")) & (~col(\"self_ref_ratio\"))).show(\n",
    "    5, truncate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89763fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erisk-env",
   "language": "python",
   "name": "erisk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
