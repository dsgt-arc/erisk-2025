{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a4ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ---------------\n",
      "aiofiles                          22.1.0\n",
      "aiosqlite                         0.18.0\n",
      "anaconda-anon-usage               0.4.3\n",
      "anaconda-client                   1.11.2\n",
      "anaconda-cloud-auth               0.1.4\n",
      "anaconda-navigator                2.5.0\n",
      "anaconda-project                  0.11.1\n",
      "anyio                             3.5.0\n",
      "appdirs                           1.4.4\n",
      "archspec                          0.2.3\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "asttokens                         2.0.5\n",
      "attrs                             22.1.0\n",
      "Babel                             2.11.0\n",
      "backcall                          0.2.0\n",
      "backports.functools-lru-cache     1.6.4\n",
      "backports.tempfile                1.0\n",
      "backports.weakref                 1.0.post1\n",
      "bash_kernel                       0.9.0\n",
      "beautifulsoup4                    4.12.2\n",
      "bleach                            4.1.0\n",
      "boltons                           23.0.0\n",
      "brotlipy                          0.7.0\n",
      "certifi                           2024.2.2\n",
      "cffi                              1.15.1\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                2.0.4\n",
      "click                             8.0.4\n",
      "clyent                            1.2.2\n",
      "comm                              0.1.2\n",
      "conda                             24.1.2\n",
      "conda-build                       3.27.0\n",
      "conda-content-trust               0.1.3\n",
      "conda_index                       0.4.0\n",
      "conda-libmamba-solver             24.1.0\n",
      "conda-pack                        0.6.0\n",
      "conda-package-handling            2.2.0\n",
      "conda_package_streaming           0.9.0\n",
      "conda-repo-cli                    1.0.41\n",
      "conda-token                       0.4.0\n",
      "conda-verify                      3.4.2\n",
      "contourpy                         1.0.5\n",
      "cryptography                      39.0.1\n",
      "cycler                            0.11.0\n",
      "daal4py                           2023.1.1\n",
      "debugpy                           1.5.1\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "distro                            1.8.0\n",
      "entrypoints                       0.4\n",
      "exceptiongroup                    1.2.0\n",
      "executing                         0.8.3\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.9.0\n",
      "fonttools                         4.25.0\n",
      "future                            0.18.3\n",
      "glob2                             0.7\n",
      "idna                              3.4\n",
      "importlib-metadata                7.0.1\n",
      "iniconfig                         2.0.0\n",
      "ipykernel                         6.19.2\n",
      "ipython                           8.12.0\n",
      "ipython-genutils                  0.2.0\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.18.1\n",
      "jeepney                           0.7.1\n",
      "Jinja2                            3.1.2\n",
      "joblib                            1.2.0\n",
      "json5                             0.9.6\n",
      "jsonpatch                         1.32\n",
      "jsonpointer                       2.1\n",
      "jsonschema                        4.17.3\n",
      "jupyter_client                    7.4.9\n",
      "jupyter-contrib-core              0.4.0\n",
      "jupyter-contrib-nbextensions      0.7.0\n",
      "jupyter_core                      5.3.0\n",
      "jupyter-events                    0.6.3\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter-latex-envs                1.4.6\n",
      "jupyter-nbextensions-configurator 0.6.1\n",
      "jupyter-server                    1.23.4\n",
      "jupyter_server_fileid             0.9.0\n",
      "jupyter_server_ydoc               0.8.0\n",
      "jupyter-ydoc                      0.2.4\n",
      "jupyterlab                        3.6.7\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.22.0\n",
      "keyring                           23.13.1\n",
      "kiwisolver                        1.4.4\n",
      "libarchive-c                      2.9\n",
      "libmambapy                        1.5.6\n",
      "lxml                              4.9.2\n",
      "MarkupSafe                        2.1.1\n",
      "matplotlib                        3.7.1\n",
      "matplotlib-inline                 0.1.6\n",
      "menuinst                          2.0.2\n",
      "mistune                           0.8.4\n",
      "mkl-fft                           1.3.6\n",
      "mkl-random                        1.2.2\n",
      "mkl-service                       2.4.0\n",
      "more-itertools                    10.1.0\n",
      "munkres                           1.1.4\n",
      "mysql-connector                   2.2.9\n",
      "navigator-updater                 0.4.0\n",
      "nb-conda-kernels                  2.3.1\n",
      "nbclassic                         0.5.5\n",
      "nbclient                          0.5.13\n",
      "nbconvert                         6.5.4\n",
      "nbformat                          5.7.0\n",
      "nest-asyncio                      1.5.6\n",
      "notebook                          6.5.4\n",
      "notebook_shim                     0.2.2\n",
      "numpy                             1.24.3\n",
      "packaging                         23.0\n",
      "pandas                            2.2.0\n",
      "pandocfilters                     1.5.0\n",
      "parso                             0.8.3\n",
      "pathlib                           1.0.1\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            9.4.0\n",
      "Pint                              0.23\n",
      "pip                               22.3.1\n",
      "pkce                              1.0.3\n",
      "pkginfo                           1.9.6\n",
      "platformdirs                      3.10.0\n",
      "pluggy                            1.0.0\n",
      "ply                               3.11\n",
      "pooch                             1.4.0\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.36\n",
      "psutil                            5.9.0\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "pycosat                           0.6.4\n",
      "pycparser                         2.21\n",
      "pydantic                          1.10.12\n",
      "Pygments                          2.15.1\n",
      "PyJWT                             2.4.0\n",
      "pyOpenSSL                         23.0.0\n",
      "pyparsing                         3.0.9\n",
      "PyQt5-sip                         12.11.0\n",
      "pyrsistent                        0.18.0\n",
      "PySocks                           1.7.1\n",
      "pytest                            7.4.4\n",
      "python-dateutil                   2.8.2\n",
      "python-dotenv                     0.21.0\n",
      "python-json-logger                2.0.7\n",
      "pytz                              2022.7\n",
      "PyYAML                            6.0\n",
      "pyzmq                             23.2.0\n",
      "QtPy                              2.2.0\n",
      "requests                          2.29.0\n",
      "requests-toolbelt                 0.9.1\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "ruamel.yaml                       0.17.21\n",
      "ruamel.yaml.clib                  0.2.6\n",
      "ruamel-yaml-conda                 0.17.21\n",
      "scikit-learn                      1.2.2\n",
      "scikit-learn-intelex              20230426.111436\n",
      "scipy                             1.10.1\n",
      "SecretStorage                     3.3.1\n",
      "semver                            2.13.0\n",
      "Send2Trash                        1.8.0\n",
      "setuptools                        65.5.0\n",
      "sip                               6.6.2\n",
      "six                               1.16.0\n",
      "sniffio                           1.2.0\n",
      "soupsieve                         2.4\n",
      "stack-data                        0.2.0\n",
      "terminado                         0.17.1\n",
      "threadpoolctl                     2.2.0\n",
      "tinycss2                          1.2.1\n",
      "toml                              0.10.2\n",
      "tomli                             2.0.1\n",
      "toolz                             0.12.0\n",
      "tornado                           6.2\n",
      "tqdm                              4.65.0\n",
      "traitlets                         5.7.1\n",
      "truststore                        0.8.0\n",
      "typing_extensions                 4.5.0\n",
      "tzdata                            2023.4\n",
      "ujson                             5.4.0\n",
      "urllib3                           1.26.15\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  0.58.0\n",
      "wheel                             0.38.4\n",
      "y-py                              0.5.9\n",
      "ypy-websocket                     0.8.2\n",
      "zipp                              3.17.0\n",
      "zstandard                         0.19.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d6e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "LABELS_MAJ_PATH = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/raw/training_data/2023/g_qrels_majority_2.csv\"\n",
    "LABELS_CONS_PATH = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/raw/training_data/2023/g_rels_consenso.csv\"\n",
    "PARQUET_DIR = \"/storage/home/hcoda1/6/dahumada3/erisk_shared/parquet/training_data/2023/partitions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6b9445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_405_1279_15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2519_356_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2038_51_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_975_61_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_577_923_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query  q0          docid  rel\n",
       "0      1   0  s_405_1279_15    1\n",
       "1      1   0   s_2519_356_0    0\n",
       "2      1   0    s_2038_51_7    1\n",
       "3      1   0     s_975_61_2    1\n",
       "4      1   0    s_577_923_1    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSVs\n",
    "majority_labels = pd.read_csv(LABELS_MAJ_PATH)\n",
    "consensus_labels = pd.read_csv(LABELS_CONS_PATH)\n",
    "\n",
    "majority_labels.columns = [\"query\", \"q0\", \"docid\", \"rel\"]\n",
    "consensus_labels.columns = [\"query\", \"q0\", \"docid\", \"rel\"]\n",
    "\n",
    "# Preview\n",
    "majority_labels.head()\n",
    "# print(\"\\n\")\n",
    "# consensus_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c6befd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_405_1279_15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2519_356_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2038_51_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_975_61_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_577_923_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query  q0          docid  rel\n",
       "0      1   0  s_405_1279_15    1\n",
       "1      1   0   s_2519_356_0    0\n",
       "2      1   0    s_2038_51_7    1\n",
       "3      1   0     s_975_61_2    0\n",
       "4      1   0    s_577_923_1    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42753815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 partition files.\n",
      "Combined shape: (4264693, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCNO</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1673_0_0</td>\n",
       "      <td>Ya that actually makes me suspicious.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1673_0_1</td>\n",
       "      <td>Bots dont do things they arent programmed to do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1673_0_2</td>\n",
       "      <td>Why would this bot be accepting mod invites fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1673_0_3</td>\n",
       "      <td>And then suddenly remove themselves.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1673_0_4</td>\n",
       "      <td>Apprentice bot might not be just a bot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DOCNO                                               TEXT\n",
       "0  s_1673_0_0              Ya that actually makes me suspicious.\n",
       "1  s_1673_0_1   Bots dont do things they arent programmed to do.\n",
       "2  s_1673_0_2  Why would this bot be accepting mod invites fr...\n",
       "3  s_1673_0_3               And then suddenly remove themselves.\n",
       "4  s_1673_0_4          Apprentice bot might not be just a bot..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all parquet files into one DataFrame\n",
    "parquet_files = [\n",
    "    os.path.join(PARQUET_DIR, f)\n",
    "    for f in os.listdir(PARQUET_DIR)\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "print(f\"Found {len(parquet_files)} partition files.\")\n",
    "\n",
    "df = pd.concat([pd.read_parquet(f) for f in sorted(parquet_files)], ignore_index=True)\n",
    "print(\"Combined shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08ff87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCNO</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4264693</td>\n",
       "      <td>4264693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4264693</td>\n",
       "      <td>3624894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>s_855_1999_0</td>\n",
       "      <td>The email shipped off your given account will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>12006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DOCNO                                               TEXT\n",
       "count        4264693                                            4264693\n",
       "unique       4264693                                            3624894\n",
       "top     s_855_1999_0  The email shipped off your given account will ...\n",
       "freq               1                                              12006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b434683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4264693 entries, 0 to 4264692\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   DOCNO   object\n",
      " 1   TEXT    object\n",
      "dtypes: object(2)\n",
      "memory usage: 65.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbde9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "Cleaned shape: (4264560, 2)\n",
      "Unique texts: 3624863\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"TEXT\"].notnull()]\n",
    "df = df[df[\"TEXT\"].str.strip().str.len() > 0]\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(\"Unique texts:\", df[\"TEXT\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ce8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "SELF_REF_PATTERNS = [\n",
    "    r\"\\bI\\b\",\n",
    "    r\"\\bI'm\\b\",\n",
    "    r\"\\bI’m\\b\",\n",
    "    r\"\\bI am\\b\",\n",
    "    r\"\\bI was\\b\",\n",
    "    r\"\\bI feel\\b\",\n",
    "    r\"\\bI think\\b\",\n",
    "    r\"\\bme\\b\",\n",
    "    r\"\\bmy\\b\",\n",
    "    r\"\\bmine\\b\",\n",
    "    r\"\\bmyself\\b\",\n",
    "    r\"\\bI've\\b\",\n",
    "    r\"\\bI’ve\\b\",\n",
    "]\n",
    "\n",
    "self_ref_regex = re.compile(\"|\".join(SELF_REF_PATTERNS), flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e6f5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-referential sentences: 1,205,375 out of 4,264,560\n"
     ]
    }
   ],
   "source": [
    "df[\"is_self_ref\"] = df[\"TEXT\"].apply(lambda x: bool(self_ref_regex.search(x)))\n",
    "\n",
    "self_ref_df = df[df[\"is_self_ref\"]].copy()\n",
    "print(f\"Self-referential sentences: {len(self_ref_df):,} out of {len(df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a54fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /storage/home/hcoda1/6/dahumada3/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Make sure tokenizer is ready\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Define self-referential word lists\n",
    "SELF_REFERENTIAL_WORDS = {\n",
    "    \"en\": {\n",
    "        \"i\",\n",
    "        \"me\",\n",
    "        \"my\",\n",
    "        \"mine\",\n",
    "        \"myself\",\n",
    "        \"i'm\",\n",
    "        \"i’ve\",\n",
    "        \"i'd\",\n",
    "        \"i’ll\",\n",
    "        \"i’d\",\n",
    "        \"i’d\",  # contractions\n",
    "        \"i’ve\",\n",
    "        \"i'd\",\n",
    "        \"i’ll\",\n",
    "        \"i’ve\",\n",
    "        \"i am\",\n",
    "        \"i was\",\n",
    "    }\n",
    "    # Extend with other languages if needed\n",
    "}\n",
    "\n",
    "\n",
    "# Function to calculate self-referential ratio\n",
    "def calculate_self_referential_ratio(text, lang=\"en\"):\n",
    "    if lang not in SELF_REFERENTIAL_WORDS or not text:\n",
    "        return 0.0\n",
    "\n",
    "    words = word_tokenize(text.lower())\n",
    "    total_words = len(words)\n",
    "\n",
    "    if total_words == 0:\n",
    "        return 0.0\n",
    "\n",
    "    self_ref_words = SELF_REFERENTIAL_WORDS[lang]\n",
    "    self_ref_count = sum(1 for word in words if word in self_ref_words)\n",
    "\n",
    "    return self_ref_count / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e48e2baf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/storage/home/hcoda1/6/dahumada3/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/share/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/storage/home/hcoda1/6/dahumada3/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/home/hcoda1/6/dahumada3/nltk_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_ref_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEXT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_self_referential_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/storage/home/hcoda1/6/dahumada3/nltk_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_ref_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEXT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalculate_self_referential_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mcalculate_self_referential_ratio\u001b[0;34m(text, lang)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SELF_REFERENTIAL_WORDS \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m total_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(words)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_words \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/storage/home/hcoda1/6/dahumada3/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/share/nltk_data'\n    - '/storage/scratch1/6/dahumada3/venvs/erisk-2025/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/storage/home/hcoda1/6/dahumada3/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "nltk.data.path.append(\"/storage/home/hcoda1/6/dahumada3/nltk_data\")\n",
    "df[\"self_ref_ratio\"] = df[\"TEXT\"].apply(\n",
    "    lambda x: calculate_self_referential_ratio(x, lang=\"en\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "203bfd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /storage/home/hcoda1/6/dahumada3/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")\n",
    "# Some issues with the latest nltk version see: https://github.com/nltk/nltk/issues/3293"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351564c",
   "metadata": {},
   "source": [
    "##### The next cell Takes too long on >4 Million posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4d31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"self_ref_ratio\"] = df[\"TEXT\"].apply(\n",
    "    lambda x: calculate_self_referential_ratio(x, lang=\"en\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f2bc805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCNO</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>is_self_ref</th>\n",
       "      <th>self_ref_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1673_0_0</td>\n",
       "      <td>Ya that actually makes me suspicious.</td>\n",
       "      <td>True</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s_1673_1_2</td>\n",
       "      <td>I checked his post history at one point and he...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s_1673_1_4</td>\n",
       "      <td>The next two are my posts.</td>\n",
       "      <td>True</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s_1673_1_5</td>\n",
       "      <td>Night Mind is a youtuber I watch who specializ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s_1673_1_6</td>\n",
       "      <td>He doesnt have the most active sub but i thoug...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264557</th>\n",
       "      <td>s_855_1863_0</td>\n",
       "      <td>I am.. sadness</td>\n",
       "      <td>True</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264561</th>\n",
       "      <td>s_855_1867_1</td>\n",
       "      <td>Source: http://pre04.deviantart.net/c6b6/th/p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264575</th>\n",
       "      <td>s_855_1881_1</td>\n",
       "      <td>Source: http://pre14.deviantart.net/9bb6/th/p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264577</th>\n",
       "      <td>s_855_1883_1</td>\n",
       "      <td>Source: http://pre12.deviantart.net/80fd/th/p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264586</th>\n",
       "      <td>s_855_1891_1</td>\n",
       "      <td>Source: http://img00.deviantart.net/2ac8/i/20...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1205375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DOCNO                                               TEXT  \\\n",
       "0          s_1673_0_0              Ya that actually makes me suspicious.   \n",
       "7          s_1673_1_2  I checked his post history at one point and he...   \n",
       "9          s_1673_1_4                         The next two are my posts.   \n",
       "10         s_1673_1_5  Night Mind is a youtuber I watch who specializ...   \n",
       "11         s_1673_1_6  He doesnt have the most active sub but i thoug...   \n",
       "...               ...                                                ...   \n",
       "4264557  s_855_1863_0                                     I am.. sadness   \n",
       "4264561  s_855_1867_1   Source: http://pre04.deviantart.net/c6b6/th/p...   \n",
       "4264575  s_855_1881_1   Source: http://pre14.deviantart.net/9bb6/th/p...   \n",
       "4264577  s_855_1883_1   Source: http://pre12.deviantart.net/80fd/th/p...   \n",
       "4264586  s_855_1891_1   Source: http://img00.deviantart.net/2ac8/i/20...   \n",
       "\n",
       "         is_self_ref  self_ref_ratio  \n",
       "0               True        0.142857  \n",
       "7               True        0.066667  \n",
       "9               True        0.142857  \n",
       "10              True        0.071429  \n",
       "11              True        0.050000  \n",
       "...              ...             ...  \n",
       "4264557         True        0.250000  \n",
       "4264561         True        0.000000  \n",
       "4264575         True        0.000000  \n",
       "4264577         True        0.000000  \n",
       "4264586         True        0.000000  \n",
       "\n",
       "[1205375 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"is_self_ref\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bb15c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCNO</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>is_self_ref</th>\n",
       "      <th>self_ref_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4264561</th>\n",
       "      <td>s_855_1867_1</td>\n",
       "      <td>Source: http://pre04.deviantart.net/c6b6/th/p...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DOCNO                                               TEXT  \\\n",
       "4264561  s_855_1867_1   Source: http://pre04.deviantart.net/c6b6/th/p...   \n",
       "\n",
       "         is_self_ref  self_ref_ratio  \n",
       "4264561         True             0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"DOCNO\"] == \"s_855_1867_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6605fab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Source: http://pre04.deviantart.net/c6b6/th/pre/i/2016/161/a/7/lighting_the_way___lux_by_zarory-da5m4js.jpgArtist: **Casper Hansen** from *Denmark*You can find more on him [here](http://zarory.deviantart.com)Software used: *Photoshop*\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df[\"DOCNO\"] == \"s_855_1867_1\", \"TEXT\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc062fb",
   "metadata": {},
   "source": [
    "#### Looks like there's still some junk posts after filtering, If self ref ratio is zero these documents can be filtered out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erisk-2025",
   "language": "python",
   "name": "erisk-2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
